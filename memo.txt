poetry run python <filename>

似非QRコードの高速姿勢トラッキング

作業リスト:
  python
    cv2.Mat <-> GPUTexture
    show GPUTexture
    関数にまとめる
  wgsl
    image result of pattern detection
      preprocess image
        grayscale
        adoptive smooth threshold
          gaussian filter
            vertical
            horizontal
          smooth_threshold
      match multi scale
        [0,1] -> [-1, 1]
        convolution
        threshold
        or (other size)
      and (vertical, horizontal)(positive, negative)
    points result of pattern detection
      collect positive, negative
      x-mean clustering (positive, negative) by pyclustering
    marker detection
      make pairs of position + 2 rotation
        convolution 1d on texture between position-rotation
        pick 2 max
        filter (threshold < 2 max)
  python
    marker to quaternion + translation
    計算結果の表示
  似非コードの印刷と撮影
  リアルタイムでの実行
  ComputeShaderでの実装
  marker再考
    memo_marker
      fisheyeパターンの変更
        kernelの合計が0になるように(畳み込みで判定する都合上)
      quaternionの計算が粗いのでdcmのまま使う
    id情報の付加
      id付きマーカーの画像出力
      実写画像からのid読み取り
        新マーカーの印刷と撮影
        MarkerIdReader
          read(src, point_pos, point_axis0, point_axis1) -> int
      id_template3への移行
        img_to_marker -> marker_id_clipper
          リサンプルするのはマーカー右下のID領域のみでよい
          グレイスケール、アフィン変換、ガウシアンフィルタ、縮小、2値化 でやる
        MarkerFormat
        align_patternを[1, -1, -1, 1]にする
          positionのfisheyeとかぶらない、畳み込みで0になる系列
        MarkerIdReader
        新マーカーの印刷と撮影
  リファクタリング
    Poetry
      pyproject.tomlの[tool.poetry]のpackages で importを整理
      汎用性のないシェーダを個別のモジュールのディレクトリに移動
    MarkerDetector, MarkerFormat, MarkerIdReader, QuickTrackMarker の関係整理
      MarkerFormat
      MarkerFinder
        SmoothThresholdFilter
        FisheyeDetector
        PointsExtractor
        PairingEvaluator
        PairFinder
        MarkerIdReader
      QcuickTrackMarker -> TrackingInfo
        id: Option<int> を持つ
  marker候補ごとのマルチスレッド
    pair_finder を単pointに変更
  実行時間の測定
    example_track_camera より marker_finder でやった方が過程ごとに細かく取れるか
  ////
  x-meansのGPU実装
    request_device(required_limits=)
      workgroup_size
    points_extractor が遅いので
    x-meansに最小距離条件を付けたい
    k2means
      var<workgroup> array<bool> の挙動がおかしい?
      calc_BIC
      //
      ワークグループ数を増やして各クラスタを並列に
    align
    copy
    xmeans
      各クラスタを並列に処理するにはワークグループ数を増やす必要がある
        py側マルチスレッドや再帰とは相性が悪そう
      test


課題
  x-mean のwgpu実行?
    compute_shaderの他の部分が遅すぎて苦しいか
    分割に最小距離条件も加えたい
  orthogonalに近似せずperspectiveのまま計算?
    orthogonalへの近似は、マーカーサイズがカメラとの距離に対して十分に小さい必要がある
    align_patternをマッチして4点にしたらAruco同様の処理でいけそう
  python - wgpu を ProtocolBuffer あたりでラップできないか?
    wgslとpy両方でBindingLayoutを書くのだるい
    自動でやってほしい
      RustのSierraとかがやってるっぽい

リファクタリング
  if -> step
  buffer類はbind_groupではなくlayoutと同時に作ってもよさそう
    データ書き込みの手間と比較したい

精度やバグ
  scale_min, scale_step を見直したほうがいいか?
  実行時間の測定
  sqrtにinfやNanが入ってくる?
  quaternionの計算が粗い?
    dcmをそのまま使ったほうが良さそう

Render vs. Compute
  render_shaderだと0.2程度
  compute_shaderだと1.3程度かかる
  どういう理由での差?
  RenderBundleにしたらもっと短くなる?


実装メモ
  command_buffer
    一度使うと消費されてしまうので実行の度に作る必要がある
  z axis flipping
    positionに対してrotationのzが反転する
    単眼カメラでは対処が厳しい
      4点あればperspectiveから可能か?
      マーカーが立体であれば可能か
  z座標について
    z座標を得るには焦点距離などが必要
    既知でない場合はカメラキャリブレーションが必要になってくる
  match_multi_scale
    別々のshaderに処理を分割してもよいか
      remap, filter_1d(convolution), threshold, boolean_ops
  wgpu.FilterMode.nearest が効いてない
  dynamic_offset - buffer_offset_alignment
    部分スライスを得たいとき不便
    offset, length を送る方法
      同じバッファをバインドしても並列化してくれるか?
    別のバッファを確保する方法
      バッファを新たに確保するのは遅そう
  compute shader
    textureSampleが使えないのでテクスチャの任意の点を取るのが面倒くさい
  render shader
    render target は2dのみ
  arrays of texture are not supported in current wgsl




Background
  マーカーの姿勢推定は、トラッキングや自己位置推定に有用
  マーカーを用いた姿勢推定はARToolkit等で提案されている
    マーカー検出処理のラベリングや輪郭検出あたりが重い
  fish eye パターンを用いたものも提案されている(論文)
    最大径を求める処理は重くないか?
  新しく高速なものを提案する
    QRコードに代表されるfish_eyeを利用する
      誤マッチしにくい
      一発の検出で全てのマーカーを見つける
    wgpuで並列化する
    状態を持たない
      混線したり見失ったトラッカーを再度初期化する必要がない


歪み補正
  レンズの歪みを補正し、ピンホールモデルにする?

マーカー仕様
  位置パターン + 姿勢パターン*2
    全マーカー共通でいいと思う
    位置と姿勢は正負反転
  id情報

パターンそれぞれの検出
  二値化
  縦横畳み込み
    畳み込み
      並列度はピクセルごと
      カーネルサイズごとに行い統合する必要がある
        統合の時間オーダーはlog(カーネルサイズ)だがcompute shaderになるし線形でいいか
      カーネルサイズごとに計算が必要なため総計算量は大きい
    cvのQRコード検出で見られるエッジ間隔の比を使う方法も候補としてあるか
      並列度は列ごとになる
      オクルージョンやノイズに弱くなるか
  縦横の結果をandする
  k-mean clustering?
  //
  k-mean clustering 以前は画素ごとに計算できる
    render bundleとして扱ってよいか?
      wgpu-native 未実装らしい

マーカーの検出と姿勢推定
  パターンが同一のマーカーに属するかの判定
    位置パターンと姿勢パターンの中心を線分でつなぎ、その上を補間しつつ畳み込み
    姿勢パターンxと姿勢パターンyについても一応確認してもよい
  x,yを得たら式に放り込んでquaternionと大きさを得る
    ピンホールモデルとorthogonalの違いに注意!!
