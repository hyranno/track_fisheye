poetry run python <filename>

似非QRコードの高速姿勢トラッキング

x-meansのGPU実装は作業量が重いし本筋でもないので後でやるか

TODO:
  python
    cv2.Mat <-> GPUTexture
    show GPUTexture
    関数にまとめる
  wgsl
    image result of pattern detection
      preprocess image
        grayscale
        adoptive smooth threshold
          gaussian filter
            vertical
            horizontal
          smooth_threshold
      match multi scale
        [0,1] -> [-1, 1]
        convolution
        threshold
        or (other size)
      and (vertical, horizontal)(positive, negative)
    points result of pattern detection
      collect positive, negative
      x-mean clustering (positive, negative) by pyclustering
    marker detection
      make pairs of position + 2 rotation
        convolution 1d on texture between position-rotation
        pick 2 max
        filter (threshold < 2 max)
  python
    marker to quaternion + translation
    計算結果の表示
  似非コードの印刷と撮影
  リアルタイムでの実行
  ComputeShaderでの実装
  //
  render版のinterfaceをcompute版と揃える
  精度やバグ
    scale_min, scale_step を見直したほうがいいか?
    実行時間の測定
    sqrtにinfやNanが入ってくる?
  fisheyeパターンの変更
    kernelの合計が0になるように(畳み込みで判定する都合上)
  x-mean のwgpu実行
    分割に最小距離条件も加えたい
  orthogonalに近似せずperspectiveのまま計算
    orthogonalへの近似は、マーカーサイズがカメラとの距離に対して十分に小さい必要がある
  python - wgpu を ProtocolBuffer あたりでラップできないか?

パターンの検出
  multiscale_matcher1d に texture_3dを使う
  畳み込みじゃないcvのQRコード方式も検討する

Render vs. Compute
  render_shaderだと0.2程度
  compute_shaderだと1.3程度かかる
  どういう理由での差?
  RenderBundleにしたらもっと短くなる?


実装メモ
  command_buffer
    一度使うと消費されてしまうので実行の度に作る必要がある
  z axis flipping
    positionに対してrotationのzが反転する
    単眼カメラでは対処が厳しい
      4点あればperspectiveから可能か?
      マーカーが立体であれば可能か
  z座標について
    z座標を得るには焦点距離などが必要
    既知でない場合はカメラキャリブレーションが必要になってくる
  match_multi_scale
    別々のshaderに処理を分割してもよいか
      remap, filter_1d(convolution), threshold, boolean_ops
  wgpu.FilterMode.nearest が効いてない
  compute shader
    textureSampleが使えないのでテクスチャの任意の点を取るのが面倒くさい
  render shader
    render target は2dのみ
  arrays of texture are not supported in current wgsl
  gaussian blur
    one big kernel will be efficient rather than repeated blur
    total_kernel_size = sqrt(num_loop) * kernel_size




Background
  マーカーの姿勢推定は、トラッキングや自己位置推定に有用
  マーカーを用いた姿勢推定はARToolkit等で提案されている
    マーカー検出処理のラベリングや輪郭検出あたりが重い
  fish eye パターンを用いたものも提案されている(論文)
    最大径を求める処理は重くないか?
  新しく高速なものを提案する
    QRコードに代表されるfish_eyeを利用する
    wgpuで並列化する


歪み補正
  レンズの歪みを補正し、ピンホールモデルにする?

マーカー仕様
  位置パターン + 姿勢パターン*2
    全マーカー共通でいいと思う
    位置と姿勢は正負反転
  id情報

パターンそれぞれの検出
  二値化
  縦横畳み込み
    畳み込み
      並列度はピクセルごと
      カーネルサイズごとに行い統合する必要がある
        統合の時間オーダーはlog(カーネルサイズ)だがcompute shaderになるし線形でいいか
      カーネルサイズごとに計算が必要なため総計算量は大きい
    cvのQRコード検出で見られるエッジ間隔の比を使う方法も候補としてあるか
      並列度は列ごとになる
      オクルージョンやノイズに弱くなるか
  縦横の結果をandする
  k-mean clustering?
  //
  k-mean clustering 以前は画素ごとに計算できる
    render bundleとして扱ってよいか?
      wgpu-native 未実装らしい

マーカーの検出と姿勢推定
  パターンが同一のマーカーに属するかの判定
    位置パターンと姿勢パターンの中心を線分でつなぎ、その上を補間しつつ畳み込み
    姿勢パターンxと姿勢パターンyについても一応確認してもよい
  x,yを得たら式に放り込んでquaternionと大きさを得る
    ピンホールモデルとorthogonalの違いに注意!!
